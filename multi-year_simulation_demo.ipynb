{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b91df9-0684-4408-b049-546d0a037599",
   "metadata": {},
   "source": [
    "# Coupled dFLWL-EFO and GDROM for multi-year operation simulation\n",
    "\n",
    "In this demo, we implement the coupled dFLWL-EFO and GDROM to multi-year operation simulation (WYs 2015-2019) in Folsom Lake. In each year, dFLWL-EFO is applied to the major flood season (November 18 to February 28/29), while the GDROM model is used to simulate real-world release in the non-flood season (June 1 to November 18). For the late flood season (March 1 to May 31), daily releases are determined by the modified storage regulation curve associated with the experiment settings. \n",
    "\n",
    "In multi-year operation simulation, GDROM plays multiple roles as summarized below: \n",
    "- During the major flood season, M1 is used to determine daily $R_{1,min}$ to meet various water demand. \n",
    "- During the non-flood season, the entire operation rules (two modules & module transition conditions) derived by GDROM are used to determine daily release $R_{1}$.\n",
    "\n",
    "Basic model settings are consistant with those for implementing dFLWL-EFO for the flood season of WY 2017. The difference is that for multi-year operation simulation, we provide additional rules to deal with extreme droughts. Besides, the modified storage regulation curve is provided to guide late flood season operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396c7bb2-99ae-42ec-ad95-9258cffefa4e",
   "metadata": {},
   "source": [
    "## import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa112c9-2038-42a0-84fa-139da418b6a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modules defined in this study\n",
    "from utils import bma_module # functions to implement BMA to generate BMA-PDFs of forecasted inflow within the forecast horizon\n",
    "from utils import efo_model # functions to implement the EFO\n",
    "from utils import dflwl_model # functions to implement the modified dFLWL model to utilize the BMA-PDFs\n",
    "from utils import gdrom_folsom # pre-derived operations rules for Folsom Lake via the GDROM \n",
    "\n",
    "\n",
    "# other modules used in this notebook\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2925201-dcbe-4431-997b-9086426ef9bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model setting\n",
    "- based on real-world operational constraints & operators' preferences and judgements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf2db97-297e-4ab9-848f-c2eb97f90cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%%%% real-world storage regulation curve (only considering major flood season)\n",
    "# units: TAF (thousand acre-feet)\n",
    "# res_S_max, S_old_conser are associated with reservoir attributes, which can be obtained from the real-world rule curve \n",
    "# W_N: the storage difference btw. the target water conservation level at the end of flood season and the FLWL (i.e., the upper bound of original water conservation pool); \n",
    "\n",
    "res_S_max = 967 # usable storage capacity (i.e., storage corresponding to target water conservation level by the end of flood season)\n",
    "S_old_conser = 367 # storage corresponding to FLWL\n",
    "W_N = res_S_max - S_old_conser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc2cf2-e835-4585-953f-452fec0078f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%%%% real-world operational constraints\n",
    "# units: TAF, 1 cfs = 1.9835 acre-feet/day\n",
    "# R1, current day (i.e., Stage 1) release in volume\n",
    "# R1_min will be determined by GDROM (provided later)\n",
    "\n",
    "I_thresh = 30*1.9835 # inflow threshold to determine if there is ongoing flood at current day\n",
    "R1_max = 115*1.9835 # normal flood control objective release \n",
    "\n",
    "# Ramping rate constraints\n",
    "R1_increase_limit = 80*1.9835 # assuming I0=0 (I0, inflow rate of the previous day), calculated based on ramping rate constraints-1&2\n",
    "R1_recession_limit = 60*1.9835 # assuming I0=115 kcfs, calculated based on ramping rate constraints-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e1612-36ce-404a-91bd-d310d17de3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%%%% customizable parameters in dFLWL-EFO\n",
    "selected_horizon = 7 # selected forecast horizon\n",
    "W_max = 400 # the upper bound of carryover capacity (FIRO space) during major flood season, in TAF\n",
    "W_F = 400 # the upper bound of risk-tolerance based flood control capacity during major flood season, in TAF\n",
    "\n",
    "########## parameters of the dFLWL model\n",
    "# w: a weight assigned to flood control objective; (1-w), a weight assigned to water conservation\n",
    "# m: an conponent to define the shape of the loss function, m>1 to ensure the convexity\n",
    "w = 0.6\n",
    "m = 3\n",
    "\n",
    "# r_alpha: risk tolerance levels used in dFLWL model under a forecast horizon of 7 days \n",
    "dFLWL_r_alpha = 0.15\n",
    "\n",
    "# R2_max: downstream flood conveyance capacity at Stage 2 under a forecast horizon of 7 days \n",
    "# R2_max was derived from historical release series (unit: TAF)\n",
    "R2_max = 487.4\n",
    "\n",
    "########## parameters of the EFO model\n",
    "# risk-tolerance curve for flood control releases, which is generated based on the X1=5, X2=0.37 (at day 15)\n",
    "df_risk_tolerance = pd.read_csv(r'...\\data\\EFO_risk_tolerance_curve.csv')\n",
    "EFO_risk_tolerance = df_risk_tolerance['risk tolerance'].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f311d86-c10c-472a-a46b-0df5ec555eef",
   "metadata": {},
   "source": [
    "### additonal parameters and rules for multi-year operation simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aae243-2200-415a-bf7e-5ec88ea54d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%%%% additional parameters for multi-year operation simulation\n",
    "# a storage threhold (e.g., dead storage) to use user-defined rules under extreme drought conditions\n",
    "S_drought_critical = 300 # in TAF\n",
    "# the lower bound of daily required release under operation normal conditions (derived from GDROM)\n",
    "R1_min_lb = 3.932 # in TAF\n",
    "\n",
    "# modified storage regulation curve associated with the experiment settings.\n",
    "df_Wm = pd.read_csv(r'...\\data\\Modified_rule_curve.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc9e5f0-4d83-4a13-b845-878e5de45ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%%%%%  additional rules to ensure reservoir storage will not go zero during extreme dry conditions\n",
    "# Users can adjust the rules below to reflect different operational response to extreme droughts \n",
    "def emergency_drought_release(I1, R1_min_lb):    \n",
    "    if I1 <= R1_min_lb: \n",
    "        R1 = I1\n",
    "    else:\n",
    "        R1 = R1_min_lb\n",
    "        \n",
    "    return R1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041ab7f-1098-4406-821f-071079ba4f59",
   "metadata": {},
   "source": [
    "## Run the coupled dFLWL-EFO and GDROM for multi-year simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad12c54-ee4c-46f1-b265-029631001d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%%%%%%%%% read necessary files\n",
    "# read the folder that saves daily-updated ensemble streamflow forecasts\n",
    "daily_ens_folder = \"...\\\\data\\\\CNRFC_daily_ensemble\\\\\"\n",
    "\n",
    "# read the calibrated parameters of the BMA model (calibrated using R package 'ensembleBMA' externally)\n",
    "BMA_parameters = pd.read_csv(r'...\\data\\BMA_paras_7day_horizon.csv', usecols=[1, 2])\n",
    "# read the fitted lambda value of the Box-Cox transformation (required in implementing BMA model)\n",
    "df_lambda = pd.read_csv(r'...\\data\\Box_Cox_trans_lambda.csv') \n",
    "fitted_lambda = df_lambda.loc[df_lambda['n_day']==selected_horizon,:]['fitted_lambda'].values\n",
    "\n",
    "# read observed operation data\n",
    "df_obs = pd.read_csv(r'...\\data\\Folsom_observed_operations.csv')\n",
    "df_obs['date'] = pd.to_datetime(df_obs['date'])\n",
    "# convert units: 1 million cubic meter (mcm) = 0.8107144 thousand acre-feet\n",
    "df_obs.loc[:,'I1'] = df_obs['netinflow-mcm'] * 0.8107144\n",
    "df_obs.loc[:,'S0_obs'] = df_obs['storage-mcm'] * 0.8107144\n",
    "df_obs.loc[:,'R1_obs'] = df_obs['outflow-mcm'] * 0.8107144\n",
    "df_obs['S1_obs'] = df_obs['S0_obs'].shift(-1) # S1: daily ending storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b0d6ea-3851-487d-9e96-988af81aa770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%%%%%%%%% \n",
    "# specify the study period\n",
    "starting_date = '2015-10-1'\n",
    "ending_date = '2019-06-30'\n",
    "chosen_period = pd.date_range(start=starting_date, end=ending_date)\n",
    "# specify the number of ensemble members\n",
    "# note: the number of ensemble members during WYs 2015-2019 is 59, while during WYs 2020-2024 is 39\n",
    "ensemble_number = 59 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3c6665-fc8b-474b-9f2e-ae36d4112a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%%%%%%%%% \n",
    "# create a dataframe to save results\n",
    "df_result = pd.DataFrame(columns  = ['date', 'I1', 'R1_sim', 'W1_sim', 'S1_sim'])\n",
    "\n",
    "# model initialization\n",
    "S0 = df_obs.loc[df_obs['date'] == starting_date, 'S0_obs'].values[0] # initial storage of the study period (observed value)\n",
    "W0 = S0 - S_old_conser # initial carryover storage of the study period\n",
    "R1_0 = df_obs.loc[df_obs['date'] == starting_date, 'R1_obs'].values[0]\n",
    "\n",
    "# range of MVs of carryover storage (water conservation benefit)\n",
    "f1_W1_0 = dflwl_model.f_L1_W1(0,W_N,w,m) # MV of W1 when W1=0\n",
    "f1_W1_max = dflwl_model.f_L1_W1(W_max,W_N,w,m) # MV of W1 when W1=W_max\n",
    "print(\"range of MVs of carryover storage:\")\n",
    "print([f1_W1_0, f1_W1_max])\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "for date in chosen_period:\n",
    "    current_date = date.strftime('%Y-%m-%d')\n",
    "    print(\"****\"+current_date+\"****\")\n",
    "    \n",
    "    #%%%%%%%%%% Beginning of daily time step %%%%%%%%%%\n",
    "    # assimilate daily-updated ensemble forecasts (unit: kcfs)\n",
    "    date_file_name = date.strftime('%Y%m%d')\n",
    "    if os.path.exists(daily_ens_folder+date_file_name+'.csv'):\n",
    "        df_ensemble = pd.read_csv(daily_ens_folder+date_file_name+'.csv')\n",
    "        df_ensemble = df_ensemble.iloc[0:15,1:]*1.9835 # unit coversion - kcfs to TAF\n",
    "        ensemble_nday_lst = df_ensemble.iloc[1:(selected_horizon+1),:].sum().values.tolist() # forecasted cumulative inflow within selected horizon \n",
    "    else:\n",
    "        print(\"CNRFC ensemble forecast data is missing for the current date!\")\n",
    "        I1 = df_obs.loc[df_obs['date']==date,'I1'].values[0]\n",
    "        I1_expected = I1 # use the observed value as predicted value for approximation\n",
    "    \n",
    "    # compute forecasted inflow at current day\n",
    "    I1_expected = np.mean(df_ensemble.iloc[0,1:])\n",
    "    \n",
    "    # extract seasonal-varying W_max from the modified storage regulation curve\n",
    "    day_of_month = date.day\n",
    "    month_seq = date.month\n",
    "    DOY = date.dayofyear\n",
    "    W_max_update = df_Wm[(df_Wm['Month']==month_seq) & (df_Wm['Day']==day_of_month)]['W_max'].values[0]\n",
    "    daily_S_max = W_max_update + S_old_conser\n",
    "    \n",
    "    # %%%%%%%%%%%%%%%%%%%%%%%\n",
    "    # Scenario 1: current date is within the non-flood season \n",
    "    # --> using the GDROM to determine daily release R1\n",
    "    if (month_seq in [6,7,8,9,10,11]) and (DOY <= 322):\n",
    "        if S0 <= S_drought_critical: # apply additional rules to address very dry conditions \n",
    "            R1 = emergency_drought_release(I1_expected, R1_min_lb)\n",
    "            R1_min = R1\n",
    "        else: # apply GDROM under normal conditions\n",
    "            PDSI_obs = df_obs.loc[df_obs['date']==date,'PDSI'].values[0] # for simplicity, we use observed PDSI as input to GDROM in hindcast experiments\n",
    "            R1 = gdrom_folsom.GDROM_release_prediction(I1_expected, S0, PDSI_obs)\n",
    "            R1_min = R1\n",
    "        \n",
    "    # %%%%%%%%%%%%%%%%%%%%%%%\n",
    "    # Scenario 2: current date is within the late-flood season (March, April, May)\n",
    "    # --> using the updated storage regulation curve to determine daily release R1\n",
    "    elif month_seq in [3,4,5]:\n",
    "        # first, compute R1_min based on storage level and the derived GDROM model\n",
    "        if S0 <= S_drought_critical: # additional rules to address very dry conditions\n",
    "            R1_min = emergency_drought_release(I1_expected, R1_min_lb)\n",
    "        else:\n",
    "            R1_min = gdrom_folsom.GDROM_M1(I1_expected, S0)\n",
    "        \n",
    "        # then, using the updated rule curve to determine R1\n",
    "        if W0 >=  W_max_update:\n",
    "            R1 = I1_expected + (W0 - W_max_update)\n",
    "        else:\n",
    "            R1 = I1_expected - (W_max_update - W0)\n",
    "            \n",
    "        # additional rules to ensure the release < inflow in late-flood season\n",
    "        if R1 >= I_thresh and R1 >= I1_expected:\n",
    "            R1 = I1_expected\n",
    "    \n",
    "    \n",
    "    # %%%%%%%%%%%%%%%%%%%%%%%\n",
    "    # Scenario 3: current date is within the major flood season (Nov. 18 - Feb. 28/29)\n",
    "    # --> using the dFLWL-EFO to determine daily release\n",
    "    else: \n",
    "        # first, compute R1_min based on storage level and the derived GDROM model\n",
    "        if S0 <= S_drought_critical: # additional rules to address very dry conditions\n",
    "            R1_min = emergency_drought_release(I1_expected, R1_min_lb)\n",
    "        else:\n",
    "            R1_min = gdrom_folsom.GDROM_M1(I1_expected, S0)\n",
    "\n",
    "        #%%%%%%%%%% determine if current inflow (I_expected) >= the flood threshold (I_thresh) %%%%%%%%%% \n",
    "        # if yes, apply EFO for flood control releases\n",
    "        # if not, apply dFLWL for optimal hedging rules\n",
    "        W1_opt = -9999\n",
    "\n",
    "        # %%%%%%%%%% apply dFLWL %%%%%%%%%% \n",
    "        if I1_expected < I_thresh: # apply dFLWL\n",
    "            print(\"### implement dFLWL for optimal hedging rules ###\")\n",
    "            # generate the BMA-PDF of I2 (in cumulative volume) during the selected forecast horizon\n",
    "            final_pdf, I2_expected, delta_min, pdf_ra, I2_995, pdf_995 = bma_module.get_BMA_PDFs(current_date, ensemble_nday_lst, BMA_parameters, fitted_lambda, dFLWL_r_alpha)\n",
    "\n",
    "            # use polynomial regression to approximate a section of the BMA-PDF of I2 \n",
    "            # in this way, dFLWL can find a numerical solutions where MVs of safety margin and carryover storage are equal\n",
    "            pdf_ra, pdf_995, reg_coeff = bma_module.get_BMA_PDFs_coeff(final_pdf, R2_max, dFLWL_r_alpha)\n",
    "            f2_delta_min = w * pdf_ra\n",
    "            f2_delta_995 = w * pdf_995\n",
    "\n",
    "            # solve optimal carryover storage and saftey margin using KKT conditions\n",
    "            W1_opt, delta_opt, case_num = dflwl_model.daily_optimal_KKT(I2_expected, delta_min, f2_delta_min, I2_995, f2_delta_995, \n",
    "                                                            reg_coeff, R2_max, W_max, W_N, w, m, f1_W1_0, f1_W1_max)\n",
    "            print('optimal carryover storage: '+str(W1_opt))\n",
    "\n",
    "            # determine release decision R1 based on water balance\n",
    "            R1 = W0 + I1_expected - W1_opt\n",
    "\n",
    "        # %%%%%%%%%% apply EFO %%%%%%%%%% \n",
    "        if W1_opt == 0 or I1_expected >= I_thresh:\n",
    "            print(\"### implement EFO for flood control release ###\")\n",
    "            R1 = efo_model.EFO_flood_release(df_ensemble, S0, (W_F+S_old_conser), selected_horizon, EFO_risk_tolerance, ensemble_number, R1_min, R1_max, I1_expected)\n",
    "            print('R1: '+str(R1))\n",
    "            \n",
    "        # *********\n",
    "        # apply additional rules to adjust the release decisions from dFLWL to reduce release fluctuation\n",
    "        if W1_opt > 0 and R1 >= I_thresh and I1_expected < I_thresh:\n",
    "            R1_temp = efo_model.EFO_flood_release(df_ensemble, S0, (W_F+S_old_conser), selected_horizon, EFO_risk_tolerance, ensemble_number, R1_min, R1_max, I1_expected)\n",
    "            if R1_temp < R1 and R1_temp > I_thresh:\n",
    "                R1 = R1_temp\n",
    "            if R1_temp < I_thresh:\n",
    "                R1 = I_thresh\n",
    "                \n",
    "        # check the lower and upper bound of carryover storage W1 during major flood season\n",
    "        W1_true_temp = W0 + I1_expected - R1\n",
    "        if W1_true_temp <= 0 and W0 >= 0: # to ensure the carryover storage W1 >= 0\n",
    "            R1 = W0 + I1_expected - 0\n",
    "        if W1_true_temp <= 0 and W0 < 0:\n",
    "            R1 = W0 + I1_expected\n",
    "        if W1_true_temp > W_max: # to ensure the carryover storage W <= W_max\n",
    "            R1 = W0 + I1_expected - W_max\n",
    "\n",
    "  \n",
    "    # %%%%%%%%%% check other release and storage requirements %%%%%%%%%% \n",
    "    # check the lower and upper bound of R1\n",
    "    if R1 < R1_min:\n",
    "        R1 = R1_min\n",
    "    if R1 > R1_max:\n",
    "        if W0 + I1_expected - R1_max <= W_N:\n",
    "            R1 = R1_max\n",
    "        else:\n",
    "            R1 = W_N - W0 - I1_expected\n",
    "\n",
    "    # check ramping rate constraints\n",
    "    if R1_0 == R1_max: # decreasing rate limit\n",
    "        R1 = R1_recession_limit\n",
    "    if R1_0 < 30*1.9835 and R1 > R1_increase_limit: #increasing rate limit\n",
    "        R1 = R1_increase_limit\n",
    "    \n",
    "    #%%%%%%%%%% End of daily time step %%%%%%%%%%\n",
    "    # note: actual (i.e., observed) inflow (I1) is known at the end of a decision time step\n",
    "    # I1 is used to determine daily ending storage at Stage 1 (current step) associated with R1\n",
    "    I1 = df_obs.loc[df_obs['date']==date,'I1'].values[0]\n",
    "    W1_true = W0 + I1 - R1 \n",
    "    S1_true = W1_true + S_old_conser\n",
    "\n",
    "    # save results\n",
    "    df_result.loc[len(df_result)] = [current_date, I1, R1, W1_true, S1_true]\n",
    "    print(\"actual inflow, release decision, ending storage:\")\n",
    "    print([I1, R1, S1_true])\n",
    "    \n",
    "    # update I1_0, R1_0, S0, W0, which might be used to adjust next-step release decision\n",
    "    I1_0 = I1 \n",
    "    R1_0 = R1 \n",
    "    W0 = W1_true\n",
    "    S0 = S1_true\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643cfdd2-fd59-4e5c-b9f5-c6a6c0a4683d",
   "metadata": {},
   "source": [
    "## 4. Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc66ee-a450-40f4-9842-fe430af7c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['date'] = pd.to_datetime(df_result['date'])\n",
    "df_result = df_result.merge(df_obs[['date', 'R1_obs', 'S0_obs']], left_on='date', right_on='date')\n",
    "df_result['S1_obs'] = df_result['S0_obs'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b347abd-b90b-46bf-8b5c-dc0f77ae74b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1,figsize=(8, 5), sharex=True)\n",
    "ax[0].plot(df_result['date'], df_result['S1_sim'], color='b', label = 'simulated')\n",
    "ax[0].plot(df_result['date'], df_result['S1_obs'], color='g', linestyle='-.', label = 'observed')\n",
    "ax[0].set_ylabel('storage (TAF)',fontweight=\"bold\", fontsize=10)\n",
    "ax[0].legend(loc='upper left', bbox_to_anchor=(0.28, 1.2), ncol=3, frameon=False)\n",
    "ax[0].grid(True,which='both',linestyle='--')\n",
    "\n",
    "ax[1].plot(df_result['date'], df_result['R1_sim'], color='b', label = 'simulated')\n",
    "ax[1].plot(df_result['date'], df_result['R1_obs'], color='g', linestyle = '-.', label = 'observed')\n",
    "ax[1].fill_between(df_result[\"date\"], df_result[\"I1\"], 0, color='lightskyblue', alpha=0.5)\n",
    "ax[1].set_ylabel('release (TAF)', fontweight=\"bold\",fontsize=10)\n",
    "ax[1].grid(True,which='both',linestyle='--')\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "legend_elements = [Line2D([0], [0], marker='s', color='none', label='observed 1d-inflow',\n",
    "                          markerfacecolor='lightskyblue', markeredgecolor='none', markersize=10)]\n",
    "ax[1].legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(0, 1), ncol=1, fontsize=10, frameon=False)     \n",
    "\n",
    "#ax[1].legend(loc='upper left', bbox_to_anchor=(0, 1), ncol=1)\n",
    "ax[1].set_ylim([-5,240])\n",
    "ax[1].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9640ca92-82bd-4ec6-81df-90cc5517aa22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a655d-9390-41fa-ae39-93cdc5c2f34d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25039c93-dc98-404e-bbf7-ccfce1bcda29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
